{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (RobertaForSequenceClassification,\n",
    "                          RobertaTokenizer,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,\n",
    "                          EarlyStoppingCallback)\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('./datasets/argquality_train.csv')\n",
    "train_dataset.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "val_dataset = pd.read_csv('./datasets/argquality_val.csv')\n",
    "val_dataset.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "test_dataset = pd.read_csv('./datasets/argquality_test.csv')\n",
    "test_dataset.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Dataset.from_pandas(train_dataset)\n",
    "val_dataset = datasets.Dataset.from_pandas(val_dataset)\n",
    "test_dataset = datasets.Dataset.from_pandas(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pEhne\\anaconda\\envs\\keypoint_hyperdrive\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pEhne\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    learning_rate=2e-5,\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=1000,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=500,\n",
    "    optim='adamw_hf',\n",
    "    do_eval=True,\n",
    "    eval_steps=500,\n",
    "    evaluation_strategy='steps',\n",
    "    save_steps=500,\n",
    "    save_strategy='steps'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bf49746e5648b9b07a45a2b920f8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee012bbbc5846a7972452a4219997f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8784f94f3bc4a579c7ad025a5b7a0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_train_dataset = train_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            num_proc=1,\n",
    "            remove_columns=['text'],\n",
    "            load_from_cache_file=False,\n",
    "        )\n",
    "\n",
    "tok_val_dataset = val_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            num_proc=1,\n",
    "            remove_columns=['text'],\n",
    "            load_from_cache_file=False,\n",
    "        )\n",
    "\n",
    "tok_test_dataset = test_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            num_proc=1,\n",
    "            remove_columns=['text'],\n",
    "            load_from_cache_file=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=tok_train_dataset,\n",
    "    eval_dataset=tok_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: index. If index are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\pEhne\\anaconda\\envs\\keypoint_hyperdrive\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 18297\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6864\n",
      "  Number of trainable parameters = 124647170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5ec6a7dba64941aee1f3e0c6eb95d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: index. If index are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6571\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.22\n",
      "{'loss': 0.6571, 'learning_rate': 1e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b207556a4a74844944c0012a51de619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Configuration saved in ./results\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "0.620814859867096\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.6752459016393443\n",
      "Attempted to log scalar metric eval_f1:\n",
      "0.7798154940535734\n",
      "Attempted to log scalar metric eval_precision:\n",
      "0.6618867924528302\n",
      "Attempted to log scalar metric eval_recall:\n",
      "0.9488774682174737\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "120.8233\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "50.487\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "6.315\n",
      "Attempted to log scalar metric epoch:\n",
      "0.22\n",
      "{'eval_loss': 0.620814859867096, 'eval_accuracy': 0.6752459016393443, 'eval_f1': 0.7798154940535734, 'eval_precision': 0.6618867924528302, 'eval_recall': 0.9488774682174737, 'eval_runtime': 120.8233, 'eval_samples_per_second': 50.487, 'eval_steps_per_second': 6.315, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: index. If index are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.605\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.44\n",
      "{'loss': 0.605, 'learning_rate': 2e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f581cf16f7384b4aa6c1c347cc6d5d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-1000\n",
      "Configuration saved in ./results\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "0.6545706391334534\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.6821311475409836\n",
      "Attempted to log scalar metric eval_f1:\n",
      "0.7813240103755498\n",
      "Attempted to log scalar metric eval_precision:\n",
      "0.6700193423597679\n",
      "Attempted to log scalar metric eval_recall:\n",
      "0.9369759264268326\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "119.8909\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "50.88\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "6.364\n",
      "Attempted to log scalar metric epoch:\n",
      "0.44\n",
      "{'eval_loss': 0.6545706391334534, 'eval_accuracy': 0.6821311475409836, 'eval_f1': 0.7813240103755498, 'eval_precision': 0.6700193423597679, 'eval_recall': 0.9369759264268326, 'eval_runtime': 119.8909, 'eval_samples_per_second': 50.88, 'eval_steps_per_second': 6.364, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-1000\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: index. If index are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6311\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.8294679399727152e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.66\n",
      "{'loss': 0.6311, 'learning_rate': 1.8294679399727152e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b1ef15b4344f99ab96ce7dda187f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-1500\n",
      "Configuration saved in ./results\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "0.5888082385063171\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.6990163934426229\n",
      "Attempted to log scalar metric eval_f1:\n",
      "0.7720953326713009\n",
      "Attempted to log scalar metric eval_precision:\n",
      "0.7134663913741683\n",
      "Attempted to log scalar metric eval_recall:\n",
      "0.8412226129294023\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "125.1305\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "48.749\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "6.098\n",
      "Attempted to log scalar metric epoch:\n",
      "0.66\n",
      "{'eval_loss': 0.5888082385063171, 'eval_accuracy': 0.6990163934426229, 'eval_f1': 0.7720953326713009, 'eval_precision': 0.7134663913741683, 'eval_recall': 0.8412226129294023, 'eval_runtime': 125.1305, 'eval_samples_per_second': 48.749, 'eval_steps_per_second': 6.098, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-1500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: index. If index are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6061\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.65893587994543e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.87\n",
      "{'loss': 0.6061, 'learning_rate': 1.65893587994543e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0584360ae04289bba588169ad16866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-2000\n",
      "Configuration saved in ./results\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "0.5971350073814392\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.7055737704918033\n",
      "Attempted to log scalar metric eval_f1:\n",
      "0.7758921886698278\n",
      "Attempted to log scalar metric eval_precision:\n",
      "0.7201760481816076\n",
      "Attempted to log scalar metric eval_recall:\n",
      "0.8409521233432513\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "119.7908\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "50.922\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "6.369\n",
      "Attempted to log scalar metric epoch:\n",
      "0.87\n",
      "{'eval_loss': 0.5971350073814392, 'eval_accuracy': 0.7055737704918033, 'eval_f1': 0.7758921886698278, 'eval_precision': 0.7201760481816076, 'eval_recall': 0.8409521233432513, 'eval_runtime': 119.7908, 'eval_samples_per_second': 50.922, 'eval_steps_per_second': 6.369, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-2000\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-1000 (score: 0.7813240103755498).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric train_runtime:\n",
      "1678.7333\n",
      "Attempted to log scalar metric train_samples_per_second:\n",
      "32.698\n",
      "Attempted to log scalar metric train_steps_per_second:\n",
      "4.089\n",
      "Attempted to log scalar metric total_flos:\n",
      "4209776885760000.0\n",
      "Attempted to log scalar metric train_loss:\n",
      "0.6248420867919922\n",
      "Attempted to log scalar metric epoch:\n",
      "0.87\n",
      "{'train_runtime': 1678.7333, 'train_samples_per_second': 32.698, 'train_steps_per_second': 4.089, 'train_loss': 0.6248420867919922, 'epoch': 0.87}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.6248420867919922, metrics={'train_runtime': 1678.7333, 'train_samples_per_second': 32.698, 'train_steps_per_second': 4.089, 'train_loss': 0.6248420867919922, 'epoch': 0.87})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: index. If index are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 6100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3598cefdbc429fbbdf21ff91ba07a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = trainer.predict(tok_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6855737704918032,\n",
       " 'f1': 0.7857940585213312,\n",
       " 'precision': 0.6693302891933028,\n",
       " 'recall': 0.9513250405624663}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/roberta_base_arg_20/\n",
      "Configuration saved in ./results/roberta_base_arg_20/config.json\n",
      "Model weights saved in ./results/roberta_base_arg_20/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./results/roberta_base_arg_20/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at C:\\Users\\pEhne/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\pEhne/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\pEhne/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/roberta_base_arg_20/tokenizer_config.json\n",
      "Special tokens file saved in ./results/roberta_base_arg_20/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./results/roberta_base_arg_20/tokenizer_config.json',\n",
       " './results/roberta_base_arg_20/special_tokens_map.json',\n",
       " './results/roberta_base_arg_20/vocab.json',\n",
       " './results/roberta_base_arg_20/merges.txt',\n",
       " './results/roberta_base_arg_20/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_MODEL = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(BASE_MODEL)\n",
    "tokenizer.save_pretrained('./results/roberta_base_arg_20/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keypoint_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52fe7d7601dac5af3c1ad97d2051df4e3be03ed5d0930aa9b612884a92ba3b64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
